{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c06576f3-0d3f-4b4a-a8ca-0e209fcc2f1b",
   "metadata": {},
   "source": [
    "Handwritten Text Recognition (HTR) is a Sequence-to-sequence (Seq2Seq) task, which is a specialized form of Structured Output that goes beyond simple image classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "faf973d8-186d-4692-a3dd-1159bfa0cfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "727a1db9-0478-4fae-b2a8-3f5c6834e4ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aa1.png</td>\n",
       "      <td>Молдова</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aa1007.png</td>\n",
       "      <td>продолжила борьбу</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aa101.png</td>\n",
       "      <td>разработанные</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aa1012.png</td>\n",
       "      <td>Плачи</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aa1013.png</td>\n",
       "      <td>Гимны богам</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72281</th>\n",
       "      <td>yob20539.png</td>\n",
       "      <td>Ответственность в/сл-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72282</th>\n",
       "      <td>yob20543.png</td>\n",
       "      <td>независимо</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72283</th>\n",
       "      <td>yob20544.png</td>\n",
       "      <td>от воинского звания</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72284</th>\n",
       "      <td>yob20545.png</td>\n",
       "      <td>воинской</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72285</th>\n",
       "      <td>yob20546.png</td>\n",
       "      <td>должности рав-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72286 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           filename                   line\n",
       "0           aa1.png                Молдова\n",
       "1        aa1007.png      продолжила борьбу\n",
       "2         aa101.png          разработанные\n",
       "3        aa1012.png                  Плачи\n",
       "4        aa1013.png            Гимны богам\n",
       "...             ...                    ...\n",
       "72281  yob20539.png  Ответственность в/сл-\n",
       "72282  yob20543.png             независимо\n",
       "72283  yob20544.png    от воинского звания\n",
       "72284  yob20545.png               воинской\n",
       "72285  yob20546.png         должности рав-\n",
       "\n",
       "[72286 rows x 2 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the tsv\n",
    "train_df = pd.read_csv(\"./archive/train.tsv\", sep=\"\\t\", header=None)\n",
    "test_df = pd.read_csv(\"./archive/test.tsv\", sep=\"\\t\", header=None)\n",
    "# val_df = pd.read_csv(\"./archive/test.tsv\", sep=\"\\t\", header=None)\n",
    "\n",
    "# val_df.columns = [\"filename\", \"line\"]\n",
    "train_df.columns = [\"filename\", \"line\"]\n",
    "test_df.columns = [\"filename\", \"line\"]\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f25048e2-9da9-4e20-843c-c979a44bd49f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad samples containing non-cyrillic letters:\n",
      "\n",
      "filename    dem35055.png\n",
      "line                 ИhМ\n",
      "Name: 37735, dtype: object\n",
      "\n",
      "filename      pe4578.png\n",
      "line        R-эффективна\n",
      "Name: 47799, dtype: object\n",
      "\n",
      "filename    yob7358.png\n",
      "line         применения\n",
      "Name: 65613, dtype: object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing\n",
    "def tokenize(line):\n",
    "    line = line.lower()\n",
    "    tokens = line.split()\n",
    "    return tokens\n",
    "\n",
    "\n",
    "# Identify rows with missing values\n",
    "missing_vals_rows = train_df[train_df['line'].isna()]\n",
    "# 63652\tyob3873.png\tNaN\n",
    "# 64127\tyob4721.png\tNaN\n",
    "\n",
    "# Get rid of rows with NaN values\n",
    "train_df.dropna(inplace=True)\n",
    "test_df.dropna(inplace=True)\n",
    "# val_df.dropna(inplace=True)\n",
    "\n",
    "# Get rid of bad rows containing latin or non-cyrillic chars\n",
    "print(\"Bad samples containing non-cyrillic letters:\\n\")\n",
    "print(train_df.iloc[37735], end='\\n\\n')\n",
    "print(train_df.iloc[47799], end='\\n\\n')\n",
    "print(train_df.iloc[65611], end='\\n\\n')\n",
    "\n",
    "train_df.drop(index=37735, inplace=True)\n",
    "train_df.drop(index=47799, inplace=True)\n",
    "train_df.drop(index=65611, inplace=True)\n",
    "\n",
    "# Reset index, to generate new indexing\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)\n",
    "# val_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "af73008d-8843-4166-984b-0cf7c17c2d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename    dem35057.png\n",
      "line               кагра\n",
      "Name: 37735, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(train_df.iloc[37735])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1104e32f-4798-4566-8b96-ee2faf24be96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>line</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aa1.png</td>\n",
       "      <td>Молдова</td>\n",
       "      <td>[молдова]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aa1007.png</td>\n",
       "      <td>продолжила борьбу</td>\n",
       "      <td>[продолжила, борьбу]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aa101.png</td>\n",
       "      <td>разработанные</td>\n",
       "      <td>[разработанные]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aa1012.png</td>\n",
       "      <td>Плачи</td>\n",
       "      <td>[плачи]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aa1013.png</td>\n",
       "      <td>Гимны богам</td>\n",
       "      <td>[гимны, богам]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72276</th>\n",
       "      <td>yob20539.png</td>\n",
       "      <td>Ответственность в/сл-</td>\n",
       "      <td>[ответственность, в/сл-]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72277</th>\n",
       "      <td>yob20543.png</td>\n",
       "      <td>независимо</td>\n",
       "      <td>[независимо]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72278</th>\n",
       "      <td>yob20544.png</td>\n",
       "      <td>от воинского звания</td>\n",
       "      <td>[от, воинского, звания]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72279</th>\n",
       "      <td>yob20545.png</td>\n",
       "      <td>воинской</td>\n",
       "      <td>[воинской]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72280</th>\n",
       "      <td>yob20546.png</td>\n",
       "      <td>должности рав-</td>\n",
       "      <td>[должности, рав-]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72281 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           filename                   line                    tokens\n",
       "0           aa1.png                Молдова                 [молдова]\n",
       "1        aa1007.png      продолжила борьбу      [продолжила, борьбу]\n",
       "2         aa101.png          разработанные           [разработанные]\n",
       "3        aa1012.png                  Плачи                   [плачи]\n",
       "4        aa1013.png            Гимны богам            [гимны, богам]\n",
       "...             ...                    ...                       ...\n",
       "72276  yob20539.png  Ответственность в/сл-  [ответственность, в/сл-]\n",
       "72277  yob20543.png             независимо              [независимо]\n",
       "72278  yob20544.png    от воинского звания   [от, воинского, звания]\n",
       "72279  yob20545.png               воинской                [воинской]\n",
       "72280  yob20546.png         должности рав-         [должности, рав-]\n",
       "\n",
       "[72281 rows x 3 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"tokens\"] = train_df[\"line\"].apply(tokenize)\n",
    "test_df[\"tokens\"] = test_df[\"line\"].apply(tokenize)\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4d0f5aa-e95f-46a8-97b6-042ac60e5a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary successfully built: 69 total characters\n",
      "char2idx vocab:  {'<BLANK>': 0, ' ': 1, '!': 2, '\"': 3, '%': 4, \"'\": 5, '(': 6, ')': 7, '+': 8, ',': 9, '-': 10, '.': 11, '/': 12, '0': 13, '1': 14, '2': 15, '3': 16, '4': 17, '5': 18, '6': 19, '7': 20, '8': 21, '9': 22, ':': 23, ';': 24, '=': 25, '?': 26, '[': 27, ']': 28, 'c': 29, 'x': 30, 'y': 31, '«': 32, '»': 33, 'а': 34, 'б': 35, 'в': 36, 'г': 37, 'д': 38, 'е': 39, 'ж': 40, 'з': 41, 'и': 42, 'й': 43, 'к': 44, 'л': 45, 'м': 46, 'н': 47, 'о': 48, 'п': 49, 'р': 50, 'с': 51, 'т': 52, 'у': 53, 'ф': 54, 'х': 55, 'ц': 56, 'ч': 57, 'ш': 58, 'щ': 59, 'ъ': 60, 'ы': 61, 'ь': 62, 'э': 63, 'ю': 64, 'я': 65, 'ё': 66, '№': 67, '<UNK>': 68}\n"
     ]
    }
   ],
   "source": [
    "# Build a vocab\n",
    "import unicodedata\n",
    "\n",
    "def build_char_vocab(df, text_col='line', lowercase=True, add_blank=True, add_unseen=True):\n",
    "    chars = set()\n",
    "    for index, text in df[text_col].items():\n",
    "        if not isinstance(text, str):\n",
    "            continue\n",
    "\n",
    "        # normalize unicode (important for cyrillic)\n",
    "        # bc these chars have multiple valid ways to encode a single visual\n",
    "        # character, 'NFC' - Normalization Form C\n",
    "        text = unicodedata.normalize('NFC', text)\n",
    "        text = text.lower() if lowercase else text\n",
    "\n",
    "        # update the character set (including punctuation and spaces)\n",
    "        chars.update(list(text))\n",
    "    \n",
    "    sorted_chars = sorted(chars)\n",
    "    \n",
    "    # Build mappings\n",
    "    char2idx = {}\n",
    "    idx = 0\n",
    "\n",
    "    # Start by adding special symbols\n",
    "    if add_blank:\n",
    "        char2idx['<BLANK>'] = idx\n",
    "        idx += 1\n",
    "\n",
    "    for ch in sorted_chars:\n",
    "        char2idx[ch] = idx\n",
    "        idx += 1\n",
    "\n",
    "    if add_unseen:\n",
    "        char2idx['<UNK>'] = idx\n",
    "\n",
    "    # Build reverse mapping\n",
    "    idx2char = {val: key for key, val in char2idx.items()}\n",
    "\n",
    "    print(f\"Vocabulary successfully built: {len(char2idx)} total characters\")\n",
    "\n",
    "    return char2idx, idx2char\n",
    "\n",
    "char2idx, idx2char = build_char_vocab(df=train_df, text_col='line')\n",
    "\n",
    "print(\"char2idx vocab: \", char2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebae902a-f3c4-48d0-a0c8-059daf264d95",
   "metadata": {},
   "source": [
    "### Encoding and decoding for characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad1e2b7d-83d1-4313-86b4-7d09fa8c87c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Привет! -> [49, 50, 42, 36, 39, 52, 2] -> привет!\n"
     ]
    }
   ],
   "source": [
    "def text_to_indices(text, char2idx):\n",
    "    text = unicodedata.normalize('NFC', text).lower()\n",
    "    indices = []\n",
    "    for ch in text:\n",
    "        if ch in char2idx and ch != '<BLANK>':\n",
    "            indices.append(char2idx[ch])\n",
    "        else:\n",
    "            indices.append(char2idx['<UNK>'])\n",
    "    return indices\n",
    "\n",
    "def indices_to_text(indices, idx2char):\n",
    "    text = \"\"\n",
    "    for i in indices:\n",
    "        text += idx2char[i] if idx2char[i] != '<BLANK>' else ''\n",
    "    return text\n",
    "\n",
    "\n",
    "# The <BLANK> is reserved for CTC, <UKN> for unseen chars\n",
    "\n",
    "sample = \"Привет!\"\n",
    "encoded = text_to_indices(sample, char2idx)\n",
    "decoded = indices_to_text(encoded, idx2char)\n",
    "\n",
    "print(sample, \"->\", encoded, \"->\", decoded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3556b5d7-a95b-4309-834c-968e14012f73",
   "metadata": {},
   "source": [
    "### Subset of the train_df\n",
    "To ease the task, we first try to feed our model single word input that should correspond to a single output. For that reason we create another dataset which is a subset of **train_df** (similarly, with test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1b7a156d-5d5f-4745-b85c-079b771a43ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>line</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aa1.png</td>\n",
       "      <td>Молдова</td>\n",
       "      <td>[молдова]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aa101.png</td>\n",
       "      <td>разработанные</td>\n",
       "      <td>[разработанные]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aa1012.png</td>\n",
       "      <td>Плачи</td>\n",
       "      <td>[плачи]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aa1017.png</td>\n",
       "      <td>(вспомнить</td>\n",
       "      <td>[(вспомнить]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aa1018.png</td>\n",
       "      <td>миф</td>\n",
       "      <td>[миф]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64972</th>\n",
       "      <td>yob20531.png</td>\n",
       "      <td>бедствий</td>\n",
       "      <td>[бедствий]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64973</th>\n",
       "      <td>yob20534.png</td>\n",
       "      <td>обст-ах</td>\n",
       "      <td>[обст-ах]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64974</th>\n",
       "      <td>yob20535.png</td>\n",
       "      <td>исп-ют</td>\n",
       "      <td>[исп-ют]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64975</th>\n",
       "      <td>yob20543.png</td>\n",
       "      <td>независимо</td>\n",
       "      <td>[независимо]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64976</th>\n",
       "      <td>yob20545.png</td>\n",
       "      <td>воинской</td>\n",
       "      <td>[воинской]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64977 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           filename           line           tokens\n",
       "0           aa1.png        Молдова        [молдова]\n",
       "1         aa101.png  разработанные  [разработанные]\n",
       "2        aa1012.png          Плачи          [плачи]\n",
       "3        aa1017.png     (вспомнить     [(вспомнить]\n",
       "4        aa1018.png            миф            [миф]\n",
       "...             ...            ...              ...\n",
       "64972  yob20531.png       бедствий       [бедствий]\n",
       "64973  yob20534.png        обст-ах        [обст-ах]\n",
       "64974  yob20535.png         исп-ют         [исп-ют]\n",
       "64975  yob20543.png     независимо     [независимо]\n",
       "64976  yob20545.png       воинской       [воинской]\n",
       "\n",
       "[64977 rows x 3 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Filter\n",
    "# single_token_train_df = train_df[train_df[\"tokens\"].apply(len) == 1]\n",
    "# single_token_train_df.reset_index(drop=True, inplace=True)\n",
    "# single_token_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38f0c852-b21a-4e9f-97af-469b4e748569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For testing purposes:\n",
    "def depict(image, label_tensor, label_str):\n",
    "    image_copy = image.squeeze(0)\n",
    "    plt.imshow(image_copy, cmap=\"gray\")\n",
    "    plt.title(label_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ed4505-8c94-4bac-bba7-5aa1b63dde6e",
   "metadata": {},
   "source": [
    "Batching: All images in a batch must have the exact same shape (e.g., 1×64×W \n",
    "max).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28558ffe-39a7-4277-b169-d0f248eb9f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "# from torchvision.transforms import ToTensor\n",
    "\n",
    "import unicodedata\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from IPython.display import Image\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def resize_with_aspect(np_image, target_height):\n",
    "    if np_image is None:\n",
    "        return None\n",
    "\n",
    "    aspect_ratio = target_height / np_image.shape[0]\n",
    "    target_width = int(np_image.shape[1] * aspect_ratio)\n",
    "    dim = (target_width, target_height)\n",
    "    image = cv2.resize(np_image, dsize=dim, interpolation=cv2.INTER_AREA)\n",
    "    return image\n",
    "\n",
    "def pad_to_width(np_image, max_width):\n",
    "    orig_width = np_image.shape[1]\n",
    "    delta_w = max_width - orig_width\n",
    "    if delta_w > 0:\n",
    "        return cv2.copyMakeBorder(\n",
    "            src=np_image, top=0, bottom=0, left=0,\n",
    "            right=delta_w,  # Padding only from the right side\n",
    "            borderType=cv2.BORDER_CONSTANT,\n",
    "            value=0 # grayscale black padding\n",
    "        )\n",
    "    return np_image\n",
    "\n",
    "\n",
    "class CyrillicHandwritingDataset(Dataset):\n",
    "    def __init__(self, dataframe, images_dir, image_height=64, transform=None, char2idx=None):\n",
    "        self.data = dataframe\n",
    "        self.images_dir = images_dir\n",
    "        self.image_height = image_height\n",
    "        self.transform = transform  # convert an image to a tensor\n",
    "        self.char2idx = char2idx\n",
    "        self.labels = [\n",
    "            ' '.join(tokens) if isinstance(tokens, list) else tokens\n",
    "            for tokens in dataframe['tokens']\n",
    "        ]\n",
    "    \n",
    "        # Load and resize images\n",
    "        self.images = self._load_and_resize_images()\n",
    "\n",
    "        # Get max width for padding\n",
    "        self.max_width = max(img.shape[1] for img in self.images)\n",
    "\n",
    "        # Pad all resized images\n",
    "        self.images = [\n",
    "            pad_to_width(image, self.max_width) for image in self.images\n",
    "        ]\n",
    "\n",
    "    def _load_and_resize_images(self):\n",
    "        \"\"\"\n",
    "        Loading and resizing with aspect\n",
    "        \"\"\"\n",
    "        resized_images = []\n",
    "        for index, row in self.data.iterrows():\n",
    "            filename = row[\"filename\"]\n",
    "            image_path = os.path.abspath(os.path.join(self.images_dir, filename))\n",
    "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            # Resize this image\n",
    "            resized_image = resize_with_aspect(image, self.image_height)\n",
    "            resized_images.append(resized_image)\n",
    "\n",
    "        return resized_images\n",
    "\n",
    "    def text_to_indices(self, text):\n",
    "        text = unicodedata.normalize('NFC', text).lower()\n",
    "        indices = []\n",
    "        for ch in text:\n",
    "            if ch in self.char2idx and ch != '<BLANK>':\n",
    "                indices.append(self.char2idx[ch])\n",
    "            else:\n",
    "                indices.append(self.char2idx['<UNK>'])\n",
    "        return indices\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        image_tensor = self.transform(image)\n",
    "        label_indices = self.text_to_indices(label)\n",
    "        label_tensor = torch.tensor(label_indices, dtype=torch.long)\n",
    "        \n",
    "        return image_tensor, label_tensor, label\n",
    "\n",
    "\n",
    "\n",
    "# Compose used to chain image transformations.\n",
    "transform_pipeline = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "    # TODO: possibly include a normalization step here once mean and std is known \n",
    "])\n",
    "\n",
    "train_set = CyrillicHandwritingDataset(\n",
    "    dataframe=train_df,\n",
    "    images_dir=\"./archive/train/\",\n",
    "    image_height=64,\n",
    "    transform=transform_pipeline,\n",
    "    char2idx=char2idx\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43762781-1d61-46ed-8414-3f62537c1a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original label: молдова\n",
      "Encoded: tensor([46, 48, 45, 38, 48, 36, 34])\n",
      "Image shape: torch.Size([1, 64, 748])\n"
     ]
    }
   ],
   "source": [
    "img, label_tensor, label_str = train_set[0]\n",
    "\n",
    "print(\"Original label:\", label_str)\n",
    "print(\"Encoded:\", label_tensor)\n",
    "print(\"Image shape:\", img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "592e93a5-ea5c-434b-919f-02369a0b8fa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "depict(*train_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed33e4b1-45e1-4b65-8959-79869e222389",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def cyrillic_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    batch: (image_tensor, label_tensor, label_str)\n",
    "    \"\"\"\n",
    "\n",
    "    batch.sort(key=lambda x: x[0].shape[-1], reverse=True)\n",
    "\n",
    "    images = [item[0] for item in batch]\n",
    "    labels = [item[1] for item in batch]\n",
    "    label_strs = [item[2] for item in batch]\n",
    "    images_padded = torch.stack(images, dim=0)\n",
    "    # All labels concatenated\n",
    "    labels_concat = torch.cat(labels)\n",
    "\n",
    "    # Effective sequence lengths after CNN\n",
    "    input_lengths = torch.full(\n",
    "        size=(len(images),),\n",
    "        fill_value=images_padded.shape[-1] // 4,\n",
    "        dtype=torch.long\n",
    "    )\n",
    "    # Label lenght (number of characters)\n",
    "    target_lengths = torch.tensor([len(label) for label in labels], dtype=torch.long)\n",
    "\n",
    "    return images_padded, labels_concat, input_lengths, target_lengths, label_strs    \n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_set,\n",
    "    batch_size=4,\n",
    "    shuffle=False,\n",
    "    collate_fn=cyrillic_collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f33d35c-7a44-43ed-b355-a62561304c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images: torch.Size([4, 1, 64, 748])\n",
      "Labels (concatenated): torch.Size([42])\n",
      "Input lengths: tensor([187, 187, 187, 187])\n",
      "Target lengths: tensor([ 7, 17, 13,  5])\n",
      "First label (string): молдова\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_loader))\n",
    "images, labels_concat, input_lengths, target_lengths, label_strs = batch\n",
    "\n",
    "print(\"Images:\", images.shape)\n",
    "print(\"Labels (concatenated):\", labels_concat.shape)\n",
    "print(\"Input lengths:\", input_lengths)\n",
    "print(\"Target lengths:\", target_lengths)\n",
    "print(\"First label (string):\", label_strs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03a04c74-622c-4a8f-92d1-062d73dfb954",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CRNN(nn.Module):\n",
    "    def __init__(self, img_height, num_classes, hidden_size=256, num_rnn_layers=2):\n",
    "        super(CRNN, self).__init__()\n",
    "\n",
    "        # --- 1. CNN feature extractor ---\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1),   # (B, 64, H, W)\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),  # ↓ H/2, W/2\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1), # (B, 128, H/2, W/2)\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),  # ↓ H/4, W/4\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),# (B, 256, H/4, W/4)\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        # compute feature size after CNN (height is fixed)\n",
    "        conv_output_height = img_height // 4  # from pooling\n",
    "\n",
    "        # --- 2. Recurrent part (BiLSTM) ---\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=256 * conv_output_height,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_rnn_layers,\n",
    "            bidirectional=True,\n",
    "            batch_first=False  # we’ll permute dims before feeding\n",
    "        )\n",
    "\n",
    "        # --- 3. Linear layer for classification ---\n",
    "        self.fc = nn.Linear(hidden_size * 2, num_classes)  # *2 for bidirectional\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, 1, H, W)\n",
    "        conv_out = self.cnn(x)  # (B, C, H', W')\n",
    "\n",
    "        B, C, H, W = conv_out.size()\n",
    "        # flatten height dimension into channels for sequence modeling\n",
    "        conv_out = conv_out.permute(3, 0, 1, 2)  # (W', B, C, H')\n",
    "        conv_out = conv_out.reshape(W, B, C * H) # (T=W', B, C*H')\n",
    "\n",
    "        # RNN expects (T, B, input_size)\n",
    "        rnn_out, _ = self.rnn(conv_out)  # (T, B, 2*hidden_size)\n",
    "        output = self.fc(rnn_out)        # (T, B, num_classes)\n",
    "\n",
    "        # For CTC loss, we need log probabilities\n",
    "        log_probs = F.log_softmax(output, dim=2)\n",
    "        return log_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "03bb76e5-c660-4707-a139-45323e57cc53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: torch.Size([4, 1, 64, 748])\n",
      "Output: torch.Size([187, 4, 69])\n"
     ]
    }
   ],
   "source": [
    "# assume: num_classes = len(char2idx)\n",
    "num_classes = len(char2idx)\n",
    "model = CRNN(img_height=64, num_classes=num_classes)\n",
    "\n",
    "# take one batch\n",
    "images, labels_concat, input_lengths, target_lengths, label_strs = next(iter(train_loader))\n",
    "log_probs = model(images)\n",
    "\n",
    "print(\"Input:\", images.shape)\n",
    "print(\"Output:\", log_probs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a2a862df-17d0-4978-b44f-8178ed1fa064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 89.0034\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CTCLoss(blank=char2idx['<BLANK>'], zero_infinity=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# (T, B, num_classes)\n",
    "log_probs = model(images)\n",
    "loss = criterion(log_probs, labels_concat, input_lengths, target_lengths)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "print(f\"Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "22a00486-dbcd-4322-86c5-6aefb29b10a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['молдова', 'продолжила борьбу', 'разработанные', 'плачи']\n",
      "Predicted: [\":'«'«!'«'«'«'«'«'«'«'«'ш2,ш\", \".'к2ш\", \":'н'н'н'йн'н'н'н'н'м'ан'нй'н'н'ь»2,ш\", '.».2ш']\n"
     ]
    }
   ],
   "source": [
    "preds = log_probs.argmax(dim=2)  # shape: (T, B)\n",
    "def greedy_decode(preds, idx2char):\n",
    "    \"\"\"\n",
    "    preds: (T, B) tensor of indices\n",
    "    \"\"\"\n",
    "    preds = preds.transpose(0, 1)  # (B, T)\n",
    "    decoded_texts = []\n",
    "\n",
    "    for pred in preds:\n",
    "        # Collapse repeated characters and remove blanks\n",
    "        prev_idx = None\n",
    "        decoded = []\n",
    "        for idx in pred:\n",
    "            idx = idx.item()\n",
    "            if idx != prev_idx and idx2char[idx] != '<BLANK>':\n",
    "                decoded.append(idx2char[idx])\n",
    "            prev_idx = idx\n",
    "        decoded_texts.append(''.join(decoded))\n",
    "    return decoded_texts\n",
    "\n",
    "\n",
    "print(label_strs)\n",
    "decoded = greedy_decode(preds, idx2char)\n",
    "print(\"Predicted:\", decoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "30fb06a3-61da-4779-838c-cf9ddcacf263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test dataset\n",
    "test_set = CyrillicHandwritingDataset(\n",
    "    dataframe=test_df,\n",
    "    images_dir=\"./archive/test/\",\n",
    "    image_height=64,\n",
    "    transform=transform_pipeline,\n",
    "    char2idx=char2idx\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "599b55c3-8555-4846-88cb-5729caa7e804",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 9036/9036 [11:19<00:00, 13.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] - Train Loss: 3.3786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 9036/9036 [11:17<00:00, 13.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10] - Train Loss: 2.3061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 9036/9036 [11:07<00:00, 13.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10] - Train Loss: 0.9992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 9036/9036 [10:55<00:00, 13.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10] - Train Loss: 0.6785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 9036/9036 [10:48<00:00, 13.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10] - Train Loss: 0.5277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 9036/9036 [10:42<00:00, 14.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10] - Train Loss: 0.4347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 9036/9036 [10:36<00:00, 14.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10] - Train Loss: 0.3656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 9036/9036 [10:40<00:00, 14.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10] - Train Loss: 0.3175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 9036/9036 [10:42<00:00, 14.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10] - Train Loss: 0.2766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 9036/9036 [10:35<00:00, 14.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] - Train Loss: 0.2479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|████████████████████████████████████████████████████████████████████| 193/193 [00:13<00:00, 13.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT: ибо\n",
      "Pred: ибо\n",
      "----------------------------------------\n",
      "GT: осталось\n",
      "Pred: осталось\n",
      "----------------------------------------\n",
      "GT: поле\n",
      "Pred: поле\n",
      "----------------------------------------\n",
      "GT: оптическое\n",
      "Pred: опичское\n",
      "----------------------------------------\n",
      "GT: 1 класса\n",
      "Pred: 1 класса\n",
      "----------------------------------------\n",
      "GT: г. ульяновск\n",
      "Pred: 2. хлоеновси\n",
      "----------------------------------------\n",
      "GT: на место\n",
      "Pred: на место\n",
      "----------------------------------------\n",
      "GT: паспорт\n",
      "Pred: пспорг\n",
      "----------------------------------------\n",
      "GT: назначение\n",
      "Pred: назначешие\n",
      "----------------------------------------\n",
      "GT: отправление\n",
      "Pred: отправлешие\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming you already have:\n",
    "# - CyrillicHandwritingDataset\n",
    "# - cyrillic_collate_fn\n",
    "# - char2idx (dictionary)\n",
    "# - idx2char (reverse mapping)\n",
    "# - train_df, test_df cleaned (NaNs dropped)\n",
    "# - transform_pipeline\n",
    "\n",
    "# ==========================\n",
    "# 1. Dataset & DataLoader\n",
    "# ==========================\n",
    "train_dataset = CyrillicHandwritingDataset(\n",
    "    dataframe=train_df,\n",
    "    images_dir=\"./archive/train/\",\n",
    "    image_height=64,\n",
    "    transform=transform_pipeline,\n",
    "    char2idx=char2idx\n",
    ")\n",
    "\n",
    "test_dataset = CyrillicHandwritingDataset(\n",
    "    dataframe=test_df,\n",
    "    images_dir=\"./archive/test/\",\n",
    "    image_height=64,\n",
    "    transform=transform_pipeline,\n",
    "    char2idx=char2idx\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=cyrillic_collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, collate_fn=cyrillic_collate_fn)\n",
    "\n",
    "# ==========================\n",
    "# 2. Define CRNN Model\n",
    "# ==========================\n",
    "class CRNN(nn.Module):\n",
    "    def __init__(self, num_classes, img_height=64):\n",
    "        super(CRNN, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 3, 1, 1),   # [B, 64, 64, W]\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),          # [B, 64, 32, W/2]\n",
    "            nn.Conv2d(64, 128, 3, 1, 1), # [B, 128, 32, W/2]\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),          # [B, 128, 16, W/4]\n",
    "        )\n",
    "\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=128 * 16,  # flatten height dimension\n",
    "            hidden_size=256,\n",
    "            num_layers=2,\n",
    "            bidirectional=True,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "        B, C, H, W = x.size()\n",
    "        x = x.permute(0, 3, 1, 2)  # [B, W, C, H]\n",
    "        x = x.reshape(B, W, C * H) # flatten H\n",
    "        x, _ = self.rnn(x)\n",
    "        x = self.fc(x)\n",
    "        x = x.permute(1, 0, 2)     # [T, B, num_classes] for CTC\n",
    "        return x\n",
    "\n",
    "# ==========================\n",
    "# 3. Model, Loss, Optimizer\n",
    "# ==========================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "num_classes = len(char2idx)\n",
    "model = CRNN(num_classes=num_classes).to(device)\n",
    "\n",
    "criterion = nn.CTCLoss(blank=char2idx['<BLANK>'], zero_infinity=True)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# ==========================\n",
    "# 4. Training Loop\n",
    "# ==========================\n",
    "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels, input_lengths, target_lengths, _ in tqdm(loader, desc=\"Training\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)  # [T, B, num_classes]\n",
    "        loss = criterion(outputs.log_softmax(2), labels, input_lengths, target_lengths)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    return running_loss / len(loader)\n",
    "\n",
    "# ==========================\n",
    "# 5. Greedy Decoding for CTC\n",
    "# ==========================\n",
    "def greedy_decode(output, idx2char):\n",
    "    out = output.argmax(dim=2).permute(1, 0)  # [B, T]\n",
    "    decoded_batch = []\n",
    "    for seq in out:\n",
    "        decoded = []\n",
    "        prev = None\n",
    "        for idx in seq:\n",
    "            char = idx2char[idx.item()]\n",
    "            if char != '<BLANK>' and char != prev:\n",
    "                decoded.append(char)\n",
    "            prev = char\n",
    "        decoded_batch.append(''.join(decoded))\n",
    "    return decoded_batch\n",
    "\n",
    "# ==========================\n",
    "# 6. Evaluation\n",
    "# ==========================\n",
    "def evaluate(model, loader, idx2char, device):\n",
    "    model.eval()\n",
    "    predictions, ground_truths = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels, input_lengths, target_lengths, label_strs in tqdm(loader, desc=\"Evaluating\"):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            preds = greedy_decode(outputs, idx2char)\n",
    "            predictions.extend(preds)\n",
    "            ground_truths.extend(label_strs)\n",
    "    return predictions, ground_truths\n",
    "\n",
    "# ==========================\n",
    "# 7. Train & Test\n",
    "# ==========================\n",
    "EPOCHS = 10\n",
    "for epoch in range(EPOCHS):\n",
    "    loss = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}] - Train Loss: {loss:.4f}\")\n",
    "\n",
    "# Evaluate after training\n",
    "preds, gts = evaluate(model, test_loader, idx2char, device)\n",
    "\n",
    "# ==========================\n",
    "# 8. Inspect Predictions\n",
    "# ==========================\n",
    "for i in range(10):\n",
    "    print(f\"GT: {gts[i]}\")\n",
    "    print(f\"Pred: {preds[i]}\")\n",
    "    print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0278f5f6-db11-44b1-86c0-34c1a6081d85",
   "metadata": {},
   "source": [
    "Connectionist Temporal Classification (CTC)\n",
    "is a specialized loss function used to train the network for sequence recognition tasks where the alignment between the input (image) and the output (text) is unknown or variable, like handwriting or speech recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8db110e2-35d2-4367-bf47-6b5297e0b698",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"crnn_cyrillic.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "59b9c438-501f-478c-a9e4-2ea297aa9993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: ибо\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint_model = torch.load(\"crnn_cyrillic.pth\")\n",
    "# checkpoint_model.eval()\n",
    "\n",
    "sample_image, _, _ = test_dataset[0]\n",
    "sample_image = sample_image.unsqueeze(0).to(device)\n",
    "\n",
    "# Forward pass\n",
    "with torch.no_grad():\n",
    "    output = model(sample_image)\n",
    "    pred_text = greedy_decode(output, idx2char)[0]\n",
    "\n",
    "depict(*test_dataset[0])\n",
    "print(f\"Predicted: {pred_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e764fab-e304-457d-b70d-d274dc96daf9",
   "metadata": {},
   "source": [
    "### Cleaner version of the existing code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5b027092-5ff1-4cf8-a163-15cf665c8dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# Dataset & DataLoader definition\n",
    "# ==========================\n",
    "\n",
    "train_dataset = CyrillicHandwritingDataset(\n",
    "    dataframe=train_df,\n",
    "    images_dir=\"./archive/train/\",\n",
    "    image_height=64,\n",
    "    transform=transform_pipeline,\n",
    "    char2idx=char2idx\n",
    ")\n",
    "\n",
    "test_dataset = CyrillicHandwritingDataset(\n",
    "    dataframe=test_df,\n",
    "    images_dir=\"./archive/test/\",\n",
    "    image_height=64,\n",
    "    transform=transform_pipeline,\n",
    "    char2idx=char2idx\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=cyrillic_collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, collate_fn=cyrillic_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d3d1f79a-d620-462d-96f1-39604c9e2862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# CRNN (CNN + RNN) Model Class\n",
    "# ==========================\n",
    "\n",
    "\n",
    "class CRNN(nn.Module):\n",
    "    def __init__(self, num_classes, img_height=64):\n",
    "        super(CRNN, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 3, 1, 1),   # [B, 64, 64, W]\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),          # [B, 64, 32, W/2]\n",
    "            nn.Conv2d(64, 128, 3, 1, 1), # [B, 128, 32, W/2]\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),          # [B, 128, 16, W/4]\n",
    "        )\n",
    "\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=128 * 16,  # flatten height dimension\n",
    "            hidden_size=256, # 256 -> 512\n",
    "            num_layers=2,\n",
    "            bidirectional=True,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "        B, C, H, W = x.size()\n",
    "        x = x.permute(0, 3, 1, 2)  # [B, W, C, H]\n",
    "        x = x.reshape(B, W, C * H) # flatten H\n",
    "        x, _ = self.rnn(x)\n",
    "        x = self.fc(x)\n",
    "        x = x.permute(1, 0, 2)     # [T, B, num_classes] for CTC\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7d9882d3-9ead-4de0-89df-0a5a7f1048ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# Model, Loss, Optimizer\n",
    "# ==========================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "num_classes = len(char2idx)\n",
    "model = CRNN(num_classes=num_classes).to(device)\n",
    "\n",
    "criterion = nn.CTCLoss(blank=char2idx['<BLANK>'], zero_infinity=True)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# ==========================\n",
    "# Training Loop\n",
    "# ==========================\n",
    "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels, input_lengths, target_lengths, _ in tqdm(loader, desc=\"Training\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)  # [T, B, num_classes]\n",
    "        loss = criterion(outputs.log_softmax(2), labels, input_lengths, target_lengths)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    return running_loss / len(loader)\n",
    "\n",
    "# ==========================\n",
    "# Evaluation\n",
    "# ==========================\n",
    "def evaluate(model, loader, idx2char, device):\n",
    "    model.eval()\n",
    "    predictions, ground_truths = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels, input_lengths, target_lengths, label_strs in tqdm(loader, desc=\"Evaluating\"):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            preds = greedy_decode(outputs, idx2char)\n",
    "            predictions.extend(preds)\n",
    "            ground_truths.extend(label_strs)\n",
    "    return predictions, ground_truths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35328e32-c79f-40fb-9690-77eb55e2a8e3",
   "metadata": {},
   "source": [
    "When using CTC (Connectionist Temporal Classification), the model doesn't predict a label for each frame directly, instead it outputs a sequence of probabilities over the whole vocabulary for each time step in the feature map.\n",
    "This output needs to be decoded into readable text.\n",
    "\n",
    "Greedy decoding method means:\n",
    "At each time step, simply pick the character with the highest probability\n",
    "It's greedy because it doesn't look ahead or consider alternate sequences (unlike **beam search decoding**)\n",
    "\n",
    "notes:\n",
    "different searching techniques: greedy, exhaustive, beam (best pay-off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "524fecb7-fe18-4fd4-b497-cadae259d0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# Greedy Decoding for CTC\n",
    "# ==========================\n",
    "def greedy_decode(output, idx2char):\n",
    "    # output of a model: (T, B, C) - time_steps, batch_size, num_classes\n",
    "    # get the index of the most probably class (hence dim=2, C)\n",
    "    out = output.argmax(dim=2).permute(1, 0)  # [B, T]\n",
    "    decoded_batch = []\n",
    "    for seq in out:\n",
    "        decoded = []\n",
    "        prev = None\n",
    "        for idx in seq:\n",
    "            char = idx2char[idx.item()]\n",
    "            if char != '<BLANK>' and char != prev:\n",
    "                decoded.append(char)\n",
    "            prev = char\n",
    "        decoded_batch.append(''.join(decoded))\n",
    "    return decoded_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d568265c-f4cc-46b0-b5f1-a1ee61c8643c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4518/4518 [09:27<00:00,  7.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] - Train Loss: 3.4878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4518/4518 [09:20<00:00,  8.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50] - Train Loss: 3.0411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4518/4518 [09:17<00:00,  8.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50] - Train Loss: 2.4642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4518/4518 [09:18<00:00,  8.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50] - Train Loss: 1.0219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4518/4518 [09:16<00:00,  8.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50] - Train Loss: 0.6306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4518/4518 [09:15<00:00,  8.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50] - Train Loss: 0.4695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4518/4518 [09:16<00:00,  8.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50] - Train Loss: 0.3656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4518/4518 [09:15<00:00,  8.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50] - Train Loss: 0.2925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4518/4518 [09:18<00:00,  8.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50] - Train Loss: 0.2382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4518/4518 [09:16<00:00,  8.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50] - Train Loss: 0.1976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4518/4518 [09:16<00:00,  8.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/50] - Train Loss: 0.1681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4518/4518 [09:18<00:00,  8.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/50] - Train Loss: 0.1454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4518/4518 [09:16<00:00,  8.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/50] - Train Loss: 0.1258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4518/4518 [09:18<00:00,  8.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/50] - Train Loss: 0.1144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4518/4518 [09:17<00:00,  8.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/50] - Train Loss: 0.1061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4518/4518 [09:17<00:00,  8.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/50] - Train Loss: 0.0939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4518/4518 [09:17<00:00,  8.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/50] - Train Loss: 0.0904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4518/4518 [09:16<00:00,  8.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/50] - Train Loss: 0.0852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4518/4518 [09:17<00:00,  8.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/50] - Train Loss: 0.0780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4518/4518 [09:16<00:00,  8.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/50] - Train Loss: 0.0761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4518/4518 [09:17<00:00,  8.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/50] - Train Loss: 0.0732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4518/4518 [09:17<00:00,  8.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/50] - Train Loss: 0.0715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4518/4518 [09:16<00:00,  8.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/50] - Train Loss: 0.0678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4518/4518 [09:18<00:00,  8.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/50] - Train Loss: 0.0662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4518/4518 [09:17<00:00,  8.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/50] - Train Loss: 0.0630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4518/4518 [09:17<00:00,  8.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/50] - Train Loss: 0.0638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4518/4518 [09:17<00:00,  8.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/50] - Train Loss: 0.0600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4518/4518 [09:16<00:00,  8.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/50] - Train Loss: 0.0601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4518/4518 [09:18<00:00,  8.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/50] - Train Loss: 0.0577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4518/4518 [09:17<00:00,  8.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/50] - Train Loss: 0.0565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4518/4518 [09:17<00:00,  8.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/50] - Train Loss: 0.0558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4518/4518 [09:17<00:00,  8.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/50] - Train Loss: 0.0549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4518/4518 [09:15<00:00,  8.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/50] - Train Loss: 0.0565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4518/4518 [09:22<00:00,  8.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/50] - Train Loss: 0.0528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4518/4518 [09:20<00:00,  8.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/50] - Train Loss: 0.0522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4518/4518 [09:21<00:00,  8.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/50] - Train Loss: 0.0515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4518/4518 [09:20<00:00,  8.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/50] - Train Loss: 0.0514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4518/4518 [09:30<00:00,  7.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/50] - Train Loss: 0.0508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4518/4518 [09:31<00:00,  7.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/50] - Train Loss: 0.0485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4518/4518 [09:26<00:00,  7.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/50] - Train Loss: 0.0496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4518/4518 [09:23<00:00,  8.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/50] - Train Loss: 0.0503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4518/4518 [09:24<00:00,  8.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/50] - Train Loss: 0.0477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4518/4518 [09:24<00:00,  8.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/50] - Train Loss: 0.0475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4518/4518 [09:20<00:00,  8.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/50] - Train Loss: 0.0467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4518/4518 [09:28<00:00,  7.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/50] - Train Loss: 0.0465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4518/4518 [09:27<00:00,  7.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/50] - Train Loss: 0.0449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4518/4518 [09:27<00:00,  7.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/50] - Train Loss: 0.0464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4518/4518 [09:28<00:00,  7.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/50] - Train Loss: 0.0447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4518/4518 [09:27<00:00,  7.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/50] - Train Loss: 0.0466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4518/4518 [09:26<00:00,  7.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/50] - Train Loss: 0.0438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 97/97 [00:17<00:00,  5.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT: ибо\n",
      "Pred: ибо\n",
      "----------------------------------------\n",
      "GT: осталось\n",
      "Pred: осталось\n",
      "----------------------------------------\n",
      "GT: поле\n",
      "Pred: поле\n",
      "----------------------------------------\n",
      "GT: оптическое\n",
      "Pred: оптическое\n",
      "----------------------------------------\n",
      "GT: 1 класса\n",
      "Pred: класса\n",
      "----------------------------------------\n",
      "GT: г. ульяновск\n",
      "Pred: 2. кльяновс\n",
      "----------------------------------------\n",
      "GT: на место\n",
      "Pred: на место\n",
      "----------------------------------------\n",
      "GT: паспорт\n",
      "Pred: песпор\n",
      "----------------------------------------\n",
      "GT: назначение\n",
      "Pred: назнячемии\n",
      "----------------------------------------\n",
      "GT: отправление\n",
      "Pred: отпровиешио\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# Train & Test\n",
    "# ==========================\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=cyrillic_collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, collate_fn=cyrillic_collate_fn)\n",
    "EPOCHS = 50\n",
    "for epoch in range(EPOCHS):\n",
    "    loss = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}] - Train Loss: {loss:.4f}\")\n",
    "\n",
    "# Evaluate after training\n",
    "preds, gts = evaluate(model, test_loader, idx2char, device)\n",
    "\n",
    "# ==========================\n",
    "# Inspect Predictions\n",
    "# ==========================\n",
    "for i in range(10):\n",
    "    print(f\"GT: {gts[i]}\")\n",
    "    print(f\"Pred: {preds[i]}\")\n",
    "    print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7f18652a-5ff8-4625-a0d6-abeb368210db",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"crnn_cyrillic_50.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f395ce68-6fa1-4df0-8d84-fd04c109be54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878b6372-e121-4377-9550-df43c753a597",
   "metadata": {},
   "outputs": [],
   "source": [
    "import esditdistance\n",
    "\n",
    "\n",
    "# Character Error Rate\n",
    "def char_err_rate(pred, target):\n",
    "    return editdistance.eval(pred, target) / max(len(target), 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5b340c-5927-4f6a-be85-788c69583cf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c537fe5-7d4c-4ae6-924b-fa1c2c7e26ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31551aa9-abdb-42ba-b00d-6a53133f49c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b90dc93-eb2c-47db-93f8-e7c1809e167d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642e49b2-9d05-4658-b187-294d5b7079dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92468177-3e10-4308-81ed-d2144aff50ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4451872e-91db-4d78-b989-108b1567137f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python GenEnv",
   "language": "python",
   "name": "gen_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
